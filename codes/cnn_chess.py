import torch
import torch.nn as nn
import torch.nn.functional as F

# Best practice: The model shouldn't know the policy size beforehand.
# We will pass it in when we create an instance of the model.

class ChessCNN(nn.Module):
    def __init__(self, policy_size):
        super(ChessCNN, self).__init__()
        # Input is 25x8x8
        self.conv1 = nn.Conv2d(25, 128, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(128)

        self.conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(128)

        self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(128)

        # The pooling layer reduces spatial dimension from 8x8 to 4x4
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        
        # Flattened size is 128 channels * 4 * 4
        self.fc1_size = 128 * 4 * 4
        
        self.fc1 = nn.Linear(self.fc1_size, 512)
        self.fc2 = nn.Linear(512, 256)

        # Value Head
        self.fc_value = nn.Linear(256, 1)

        # Policy Head - size is now passed in
        self.fc_policy = nn.Linear(256, policy_size)

    def forward(self, x):
        # Convolutional blocks with Batch Norm
        x = F.relu(self.bn1(self.conv1(x)))
        x = F.relu(self.bn2(self.conv2(x)))
        x = F.relu(self.bn3(self.conv3(x)))
        
        x = self.pool(x)
        
        # Flatten the output for the fully connected layers
        x = x.view(-1, self.fc1_size)
        
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))

        # Value head
        value = torch.tanh(self.fc_value(x))

        # Policy head
        policy = F.log_softmax(self.fc_policy(x), dim=1) # Use log_softmax for NLLLoss

        return value, policy

# Example of how to instantiate the model:
if __name__ == "__main__":
    # You would get this from your data preparation script
    # For this example, we'll use the size generated by the new script
    # This is just a placeholder value.
    EXAMPLE_POLICY_SIZE = 4096 
    
    model = ChessCNN(policy_size=EXAMPLE_POLICY_SIZE)
    print("--- Model Architecture ---")
    print(model)

    # Test with a dummy input
    # Batch of 4, 25 channels, 8x8 board
    dummy_input = torch.randn(4, 25, 8, 8)
    value_out, policy_out = model(dummy_input)

    print("\n--- Output Shapes ---")
    print(f"Value Output Shape: {value_out.shape}")   # Should be [4, 1]
    print(f"Policy Output Shape: {policy_out.shape}") # Should be [4, EXAMPLE_POLICY_SIZE]











# import torch
# import torch.nn as nn
# import torch.nn.functional as F

# class ChessCNN(nn.Module):
#     def __init__(self):
#         super(ChessCNN, self).__init__()
#         # Input is 25x8x8 (25 channels: 17 original + 8 history)
#         self.conv1 = nn.Conv2d(25, 128, kernel_size=3, padding=1)  # Output: 128x8x8
#         self.conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)  # Output: 128x8x8
#         self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)  # Output: 128x8x8
#         self.pool = nn.MaxPool2d(2, 2)  # Output: 128x4x4
#         self.fc1 = nn.Linear(128 * 4 * 4, 256)  # Flatten and connect
#         self.fc2 = nn.Linear(256, 256)
#         self.fc_value = nn.Linear(256, 1)  # Value head: position score
#         self.fc_policy = nn.Linear(256, 4672)  # Policy head: move probabilities

#     def forward(self, x):
#         x = F.relu(self.conv1(x))
#         x = F.relu(self.conv2(x))
#         x = F.relu(self.conv3(x))
#         x = self.pool(x)
#         x = x.view(-1, 128 * 4 * 4)
#         x = F.relu(self.fc1(x))
#         x = F.relu(self.fc2(x))
#         value = torch.tanh(self.fc_value(x))  # Value output: [-1, +1]
#         policy = F.softmax(self.fc_policy(x), dim=1)  # Policy output: move probabilities
#         return value, policy

# # Test the model
# if __name__ == "__main__":
#     model = ChessCNN()
#     print(model)